{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from datasets import load_metric\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from torch import cuda\n",
    "from torch.utils.data import (\n",
    "    TensorDataset,\n",
    "    DataLoader,\n",
    "    RandomSampler,\n",
    "    SequentialSampler,\n",
    "    random_split,\n",
    "    )\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    T5ForSequenceClassification,\n",
    "    T5Tokenizer,\n",
    "    )\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выбираем устройство для проведения обучения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подгружаем наши датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/in_domain_train.csv\",index_col=0)\n",
    "test_df = pd.read_csv(\"./data/in_domain_dev.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "немножко информации о них посмотрим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7869 entries, 0 to 7868\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sentence         7869 non-null   object\n",
      " 1   acceptable       7869 non-null   int64 \n",
      " 2   error_type       7869 non-null   object\n",
      " 3   detailed_source  7869 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 307.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>error_type</th>\n",
       "      <th>detailed_source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вдруг решетка беззвучно поехала в сторону, и н...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Этим летом не никуда ездили.</td>\n",
       "      <td>0</td>\n",
       "      <td>Syntax</td>\n",
       "      <td>Rusgram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Только Иван выразил какую бы то ни было готовн...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Теперь ты видишь собственными глазами, как тут...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>На поверку вся теория оказалась полной чепухой.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  acceptable error_type  \\\n",
       "id                                                                             \n",
       "0   Вдруг решетка беззвучно поехала в сторону, и н...           1          0   \n",
       "1                        Этим летом не никуда ездили.           0     Syntax   \n",
       "2   Только Иван выразил какую бы то ни было готовн...           1          0   \n",
       "3   Теперь ты видишь собственными глазами, как тут...           1          0   \n",
       "4     На поверку вся теория оказалась полной чепухой.           1          0   \n",
       "\n",
       "   detailed_source  \n",
       "id                  \n",
       "0    Paducheva2004  \n",
       "1          Rusgram  \n",
       "2    Paducheva2013  \n",
       "3    Paducheva2010  \n",
       "4    Paducheva2010  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>error_type</th>\n",
       "      <th>detailed_source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7713</th>\n",
       "      <td>Ты сейчас же взял и вылил воду!</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Rusgram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentence  acceptable error_type detailed_source\n",
       "id                                                                          \n",
       "7713  Ты сейчас же взял и вылил воду!           0  Semantics         Rusgram"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выделим необходимые для нас колонки в отдельные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_df.sentence.values\n",
    "train_labels = train_df.acceptable.values\n",
    "test_sentences = test_df.sentence.values\n",
    "test_labels = test_df.acceptable.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "я обучал на 2060, перепробовал large модели - к сожалению они не лезут. И чтобы побыстрей менять модельки - я вынес имя в отдельную переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"ai-forever/ruBert-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подгрузим токенизатор для текста из предобученной берт модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим на то как он работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное:  Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
      "Токенизированное:  ['вдруг', 'решетка', 'беззвучно', 'поехала', 'в', 'сторону', ',', 'и', 'на', 'балконе', 'возникла', 'таинственная', 'фигура', ',', 'прячу', '##щаяся', 'от', 'лунного', 'света', ',', 'и', 'погрозил', '##а', 'ива', '##ну', 'пальцем', '.']\n",
      "Идентификаторы токенов:  [3014, 83321, 41548, 32350, 113, 2931, 121, 107, 660, 50354, 13779, 99183, 15226, 121, 94376, 19913, 700, 55918, 6412, 121, 107, 95640, 377, 104691, 717, 11420, 126]\n"
     ]
    }
   ],
   "source": [
    "# Выводим исходное предложение.\n",
    "print('Исходное: ', train_sentences[0])\n",
    "\n",
    "# Выводим предложение, разделенное на токены.\n",
    "print('Токенизированное: ', tokenizer.tokenize(train_sentences[0]))\n",
    "\n",
    "# Выводим предложение, сопоставленное идентификаторам токенов.\n",
    "print('Идентификаторы токенов: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_sentences[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "найдем максимальную длину текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина текста:  45\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "for sent in train_sentences:\n",
    "\n",
    "    # токенизируем текст, не забывая добавлять специальный токен начала и конца([CLS] и [SEP])\n",
    "    train_input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Сравниваем длину последовательности и если она длиннее - обновляем max_len\n",
    "    max_len = max(max_len, len(train_input_ids))\n",
    "\n",
    "print('Максимальная длина текста: ', max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "напишем функцию токенизации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentences,tokenizer):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        # `encode_plus` выполнит следующие шаги:\n",
    "        #   (1) Токенизирует предложение.\n",
    "        #   (2) Добавит токен `[CLS]` в начало.\n",
    "        #   (3) Добавит токен `[SEP]` в конец.\n",
    "        #   (4) Сопоставит токены их идентификаторам.\n",
    "        #   (5) Дополнит или обрежет предложение до `max_length`.\n",
    "        #   (6) Создаст маски внимания для токенов [PAD].\n",
    "\n",
    "        # Используем `encode_plus` для кодирования предложения.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Предложение для кодирования.\n",
    "                            add_special_tokens = True, # Добавить '[CLS]' и '[SEP]'.\n",
    "                            max_length = 64,           # Дополнить и обрезать все предложения.\n",
    "                            pad_to_max_length = True,  # Дополнить до максимальной длины и обрезать.\n",
    "                            return_attention_mask = True,   # Создать маски внимания.\n",
    "                            return_tensors = 'pt',     # Вернуть тензоры PyTorch.\n",
    "                    )\n",
    "\n",
    "        # Добавляем закодированное предложение в список.\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # А также его маску внимания (просто отличает заполнение от незаполненного).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Возвращаем списки тензоров для input_ids и attention_masks.\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "перекодируем и приготовим наши списки к дальнейшему превращению в тензорные датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/vlamykin/git/NLP_OTUS_2023/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное предложение:  Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
      "Идентификаторы слов: tensor([   101,   3014,  83321,  41548,  32350,    113,   2931,    121,    107,\n",
      "           660,  50354,  13779,  99183,  15226,    121,  94376,  19913,    700,\n",
      "         55918,   6412,    121,    107,  95640,    377, 104691,    717,  11420,\n",
      "           126,    102,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0])\n"
     ]
    }
   ],
   "source": [
    "# Токенизируем все предложения и сопоставляем токены их идентификаторам слов.\n",
    "train_input_ids, train_attention_masks = encode(train_sentences,tokenizer)\n",
    "test_input_ids, test_attention_masks = encode(test_sentences,tokenizer)\n",
    "\n",
    "# Преобразуем списки в тензоры.\n",
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Выводим первое предложение как список идентификаторов слов.\n",
    "print('Исходное предложение: ', train_sentences[0])\n",
    "print('Идентификаторы слов:', train_input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделаем тренировочный, валидационный тензоры и приготовим тензор на котором будем тестировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,082 образцов для обучения\n",
      "  787 образцов для валидации\n"
     ]
    }
   ],
   "source": [
    "# Создаем TensorDataset из тензоров train_input_ids, train_attention_masks и train_labels.\n",
    "dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "\n",
    "# Создаем разделение данных на обучающую и валидационную выборки в пропорции 90-10.\n",
    "# Вычисляем количество образцов в каждом наборе.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Делим набор данных, случайным образом выбирая образцы.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Выводим информацию о количестве образцов в обучающей и валидационной выборках.\n",
    "print('{:>5,} образцов для обучения'.format(train_size))\n",
    "print('{:>5,} образцов для валидации'.format(val_size))\n",
    "\n",
    "# Создаем TensorDataset для тестовых данных.\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "приготовим даталоадеры для удобства обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader должен знать размер нашего батча для обучения, поэтому мы указываем его здесь.\n",
    "# При fine-tuning BERT на конкретной задаче авторы рекомендуют размер батча 16 или 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Создаем DataLoaders для наших обучающих и валидационных наборов данных.\n",
    "# Образцы для обучения будем брать в случайном порядке.\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # Обучающие образцы.\n",
    "            sampler = RandomSampler(train_dataset), # Выбираем батчи случайным образом.\n",
    "            batch_size = batch_size # Обучение с этим размером батча.\n",
    "        )\n",
    "\n",
    "# Для валидации порядок не имеет значения, поэтому мы просто читаем их последовательно.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # Валидационные образцы.\n",
    "            sampler = SequentialSampler(val_dataset), # Извлекаем батчи последовательно.\n",
    "            batch_size = batch_size # Оценка с этим размером батча.\n",
    "        )\n",
    "\n",
    "# DataLoader для тестовых данных.\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # Тестовые образцы.\n",
    "            sampler = SequentialSampler(test_dataset), # Извлекаем батчи последовательно.\n",
    "            batch_size = batch_size # Оценка с этим размером батча.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подгрузим модель и перенесем ее на графические ядра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем BertForSequenceClassification, предобученную модель BERT с одним\n",
    "# линейным слоем классификации сверху.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,       # Используем 12-слойную модель BERT с uncased словарем.\n",
    "    num_labels=4,      # Количество выходных меток -- 2 для бинарной классификации.\n",
    "                       # Можно увеличить для многоклассовых задач.\n",
    "    output_attentions=False,    # Возвращает ли модель веса внимания.\n",
    "    output_hidden_states=False, # Возвращает ли модель все скрытые состояния.\n",
    ")\n",
    "\n",
    "# Указываем PyTorch использовать GPU для выполнения этой модели.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим на параметры берта "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У модели BERT 201 различных именованных параметров.\n",
      "\n",
      "==== Слой вложения ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (120138, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== Первый трансформер ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Выходной слой ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (4, 768)\n",
      "classifier.bias                                                 (4,)\n"
     ]
    }
   ],
   "source": [
    "# Получаем все параметры модели в виде списка кортежей.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('У модели BERT {:} различных именованных параметров.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Слой вложения ====\\n')\n",
    "\n",
    "# Выводим размерности параметров для слоя вложения.\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Первый трансформер ====\\n')\n",
    "\n",
    "# Выводим размерности параметров для первого трансформера.\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Выходной слой ====\\n')\n",
    "\n",
    "# Выводим размерности параметров для выходного слоя.\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "зададим оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlamykin/git/NLP_OTUS_2023/env/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Примечание: AdamW - это класс из библиотеки huggingface (в отличие от pytorch)\n",
    "# Вероятно, 'W' означает 'Weight Decay fix' (исправление весового распада, что есть не очень понятно по звучанию).\n",
    "\n",
    "# Инициализируем оптимизатор AdamW.\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,   # Скорость обучения - по умолчанию 5e-5, в нашем случае 2e-5.\n",
    "                  eps=1e-8   # Epsilon для Adam - по умолчанию 1e-8.\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "зададим параметры обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество эпох обучения. Авторы BERT рекомендуют от 2 до 4 эпох.\n",
    "# Мы выбрали 4, но позже увидим, что это может привести к переобучению.\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "# Общее количество шагов обучения - [количество батчей] x [количество эпох].\n",
    "# (Обратите внимание, что это не то же самое, что количество обучающих образцов).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Создаем планировщик скорости обучения.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0, # Значение по умолчанию в run_glue.py.\n",
    "                                            num_training_steps=total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления точности наших предсказаний по сравнению с метками.\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Принимает время в секундах и возвращает строку в формате чч:мм:сс.\n",
    "    '''\n",
    "    # Округляем до ближайшей секунды.\n",
    "    elapsed_rounded = int(round(elapsed))\n",
    "\n",
    "    # Форматируем как чч:мм:сс\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучим модельку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Эпоха 1 / 4 ========\n",
      "Обучение...\n",
      "  Батч    40  из    222.    Затраченное время: 0:00:14.\n",
      "  Батч    80  из    222.    Затраченное время: 0:00:28.\n",
      "  Батч   120  из    222.    Затраченное время: 0:00:41.\n",
      "  Батч   160  из    222.    Затраченное время: 0:00:55.\n",
      "  Батч   200  из    222.    Затраченное время: 0:01:09.\n",
      "\n",
      "  Средняя обучающая потеря: 0.55\n",
      "  Эпоха обучения заняла: 0:01:16\n",
      "\n",
      "Запуск валидации...\n",
      "  Точность: 0.80\n",
      "  Потери валидации: 0.47\n",
      "  Валидация заняла: 0:00:03\n",
      "\n",
      "======== Эпоха 2 / 4 ========\n",
      "Обучение...\n",
      "  Батч    40  из    222.    Затраченное время: 0:00:14.\n",
      "  Батч    80  из    222.    Затраченное время: 0:00:28.\n",
      "  Батч   120  из    222.    Затраченное время: 0:00:43.\n",
      "  Батч   160  из    222.    Затраченное время: 0:00:59.\n",
      "  Батч   200  из    222.    Затраченное время: 0:01:14.\n",
      "\n",
      "  Средняя обучающая потеря: 0.35\n",
      "  Эпоха обучения заняла: 0:01:22\n",
      "\n",
      "Запуск валидации...\n",
      "  Точность: 0.80\n",
      "  Потери валидации: 0.47\n",
      "  Валидация заняла: 0:00:03\n",
      "\n",
      "======== Эпоха 3 / 4 ========\n",
      "Обучение...\n",
      "  Батч    40  из    222.    Затраченное время: 0:00:16.\n",
      "  Батч    80  из    222.    Затраченное время: 0:00:31.\n",
      "  Батч   120  из    222.    Затраченное время: 0:00:47.\n",
      "  Батч   160  из    222.    Затраченное время: 0:01:03.\n",
      "  Батч   200  из    222.    Затраченное время: 0:01:19.\n",
      "\n",
      "  Средняя обучающая потеря: 0.21\n",
      "  Эпоха обучения заняла: 0:01:27\n",
      "\n",
      "Запуск валидации...\n",
      "  Точность: 0.80\n",
      "  Потери валидации: 0.60\n",
      "  Валидация заняла: 0:00:03\n",
      "\n",
      "======== Эпоха 4 / 4 ========\n",
      "Обучение...\n",
      "  Батч    40  из    222.    Затраченное время: 0:00:16.\n",
      "  Батч    80  из    222.    Затраченное время: 0:00:32.\n",
      "  Батч   120  из    222.    Затраченное время: 0:00:48.\n",
      "  Батч   160  из    222.    Затраченное время: 0:01:04.\n",
      "  Батч   200  из    222.    Затраченное время: 0:01:20.\n",
      "\n",
      "  Средняя обучающая потеря: 0.13\n",
      "  Эпоха обучения заняла: 0:01:29\n",
      "\n",
      "Запуск валидации...\n",
      "  Точность: 0.81\n",
      "  Потери валидации: 0.67\n",
      "  Валидация заняла: 0:00:03\n",
      "\n",
      "Обучение завершено!\n",
      "Всего обучение заняло 0:05:46 (ч:м:с)\n"
     ]
    }
   ],
   "source": [
    "# Этот код обучения основан на скрипте `run_glue.py` здесь:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Устанавливаем значение seed для воспроизводимости.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Будем хранить несколько показателей, таких как обучающая и валидационная ошибка,\n",
    "# точность валидации и затраченное время.\n",
    "training_stats = []\n",
    "\n",
    "# Измерим общее время обучения для всего запуска.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# Для каждой эпохи...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Обучение\n",
    "    # ========================================\n",
    "\n",
    "    # Выполняем один полный проход по обучающему набору.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Эпоха {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Обучение...')\n",
    "\n",
    "    # Измеряем время обучения эпохи.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Сбрасываем общую ошибку для этой эпохи.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Переводим модель в режим обучения. Не путайтесь -- вызов\n",
    "    # `train` просто изменяет *режим*, он не выполняет *обучение*.\n",
    "    # `dropout` и `batchnorm` ведут себя по-разному во время обучения\n",
    "    # по сравнению с тестированием (источник: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # Для каждого батча обучающих данных...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Обновление каждые 40 батчей.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Вычисляем прошедшее время в минутах.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Сообщаем о ходе выполнения.\n",
    "            print('  Батч {:>5,}  из  {:>5,}.    Затраченное время: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Распаковываем этот батч из нашего загрузчика данных.\n",
    "        #\n",
    "        # При распаковке батча мы также копируем каждый тензор на GPU, используя\n",
    "        # метод `to`.\n",
    "        #\n",
    "        # `batch` содержит три тензора PyTorch:\n",
    "        #   [0]: идентификаторы входа\n",
    "        #   [1]: маски внимания\n",
    "        #   [2]: метки\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Всегда очищаем ранее вычисленные градиенты перед\n",
    "        # выполнением обратного прохода. PyTorch не делает это автоматически,\n",
    "        # потому что накопление градиентов \"удобно при обучении RNN\".\n",
    "        # (источник: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Выполняем прямой проход (оцениваем модель на этом обучающем батче).\n",
    "        # Документация по этой функции `model` находится здесь:\n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # Она возвращает разное количество параметров в зависимости от того, какие аргументы\n",
    "        # предоставлены и какие флаги установлены. Для нашего использования здесь она возвращает\n",
    "        # потери (поскольку мы предоставили метки) и \"логиты\" - выходные\n",
    "        # значения модели до применения активационной функции, такой как softmax.\n",
    "        res = model(b_input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             attention_mask=b_input_mask,\n",
    "                             labels=b_labels)\n",
    "        loss = res['loss']\n",
    "        logits = res['logits']\n",
    "\n",
    "        # Накапливаем обучающую потерю по всем батчам, чтобы мы могли\n",
    "        # вычислить среднюю потерю в конце. `loss` - это тензор, содержащий одно значение;\n",
    "        # функция `.item()` просто возвращает значение Python из тензора.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Выполняем обратный проход для вычисления градиентов.\n",
    "        loss.backward()\n",
    "\n",
    "        # Ограничиваем норму градиентов до 1.0.\n",
    "        # Это помогает предотвратить проблему \"взрывающихся градиентов\".\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Обновляем параметры и делаем шаг с использованием вычисленного градиента.\n",
    "        # Оптимизатор определяет \"правило обновления\" - как параметры\n",
    "        # изменяются на основе их градиентов, скорости обучения и т. д.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Обновляем скорость обучения.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Вычисляем среднюю потерю по всем батчам.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Измеряем, сколько времени заняла эта эпоха.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Средняя обучающая потеря: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Эпоха обучения заняла: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Валидация\n",
    "    # ========================================\n",
    "    # После завершения каждой обучающей эпохи измеряем нашу производительность\n",
    "    # на валидационном наборе данных.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Запуск валидации...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Переводим модель в режим оценки - слои dropout ведут себя по-другому\n",
    "    # во время оценки.\n",
    "    model.eval()\n",
    "\n",
    "    # Переменные для отслеживания\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Оцениваем данные для одной эпохи.\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Распаковываем этот батч из нашего загрузчика данных.\n",
    "        #\n",
    "        # При распаковке батча мы также копируем каждый тензор на GPU с использованием\n",
    "        # метода `to`.\n",
    "        #\n",
    "        # `batch` содержит три тензора PyTorch:\n",
    "        #   [0]: идентификаторы входа\n",
    "        #   [1]: маски внимания\n",
    "        #   [2]: метки\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Говорим PyTorch не беспокоиться о построении вычислительного графа\n",
    "        # во время прямого прохода, поскольку это нужно только для обратного\n",
    "        # распространения (обучение).\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Прямой проход, вычисляем прогнозы логитов.\n",
    "            # token_type_ids - это то же самое, что и \"segment ids\", которые\n",
    "            # различают предложения 1 и 2 в 2-предложных задачах.\n",
    "            # Документация по этой функции `model` находится здесь:\n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Получаем \"логиты\", выводимые моделью перед применением активационной функции, такой как softmax.\n",
    "            res = model(b_input_ids,\n",
    "                                   token_type_ids=None,\n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = res['loss']\n",
    "        logits = res['logits']\n",
    "\n",
    "        # Накапливаем потери валидации.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Перемещаем логиты и метки на CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Вычисляем точность для этого батча тестовых предложений и\n",
    "        # накапливаем ее по всем батчам.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Сообщаем конечную точность для этого прогона валидации.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Точность: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Вычисляем средние потери по всем батчам.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Измеряем, сколько времени занял этот прогон валидации.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Потери валидации: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Валидация заняла: {:}\".format(validation_time))\n",
    "\n",
    "    # Записываем все статистические данные из этой эпохи.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Обучающая потеря': avg_train_loss,\n",
    "            'Потери на валидации': avg_val_loss,\n",
    "            'Точность на валидации': avg_val_accuracy,\n",
    "            'Время обучения': training_time,\n",
    "            'Время валидации': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Обучение завершено!\")\n",
    "\n",
    "print(\"Всего обучение заняло {:} (ч:м:с)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим на качество модели и время её обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Обучающая потеря</th>\n",
       "      <th>Потери на валидации</th>\n",
       "      <th>Точность на валидации</th>\n",
       "      <th>Время обучения</th>\n",
       "      <th>Время валидации</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545811</td>\n",
       "      <td>0.470885</td>\n",
       "      <td>0.800329</td>\n",
       "      <td>0:01:16</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.352870</td>\n",
       "      <td>0.468839</td>\n",
       "      <td>0.804079</td>\n",
       "      <td>0:01:22</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.214832</td>\n",
       "      <td>0.595731</td>\n",
       "      <td>0.802829</td>\n",
       "      <td>0:01:27</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.128987</td>\n",
       "      <td>0.672567</td>\n",
       "      <td>0.808684</td>\n",
       "      <td>0:01:29</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Обучающая потеря  Потери на валидации  Точность на валидации  \\\n",
       "epoch                                                                 \n",
       "1              0.545811             0.470885               0.800329   \n",
       "2              0.352870             0.468839               0.804079   \n",
       "3              0.214832             0.595731               0.802829   \n",
       "4              0.128987             0.672567               0.808684   \n",
       "\n",
       "      Время обучения Время валидации  \n",
       "epoch                                 \n",
       "1            0:01:16         0:00:03  \n",
       "2            0:01:22         0:00:03  \n",
       "3            0:01:27         0:00:03  \n",
       "4            0:01:29         0:00:03  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отображаем числа с двумя десятичными знаками.\n",
    "#pd.set_option('precision', 2)\n",
    "\n",
    "# Создаем DataFrame из наших статистических данных обучения.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Используем 'epoch' в качестве индекса строк.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# Хак для принудительного переноса заголовков столбцов.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Отображаем таблицу.\n",
    "df_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "отрисуем лосс для обучающей и валидационной выборки на эпохах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Используем стиль для графиков от seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Увеличиваем размер графика и размер шрифта.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Рисуем кривую обучения.\n",
    "plt.plot(df_stats['Обучающая потеря'], 'b-o', label=\"Обучение\")\n",
    "plt.plot(df_stats['Потери на валидации'], 'g-o', label=\"Валидация\")\n",
    "\n",
    "# Даем название графику.\n",
    "plt.title(\"Обучение и потери на валидации\")\n",
    "plt.xlabel(\"Эпоха\")\n",
    "plt.ylabel(\"Потери\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "протеструем модель на тестовом наборе данных, который подгрузили и разбили так же в начале из отдельного файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогноз меток для 983 тестовых предложений...\n",
      "    ГОТОВО.\n"
     ]
    }
   ],
   "source": [
    "# Прогнозирование на тестовом наборе данных\n",
    "\n",
    "print('Прогноз меток для {:,} тестовых предложений...'.format(len(test_input_ids)))\n",
    "\n",
    "# Переводим модель в режим оценки\n",
    "model.eval()\n",
    "\n",
    "# Переменные для отслеживания\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Прогнозируем\n",
    "for batch in test_dataloader:\n",
    "  # Добавляем батч на GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Распаковываем входы из нашего загрузчика данных\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # Скажем модели не вычислять или хранить градиенты, экономя память и\n",
    "  # ускоряя прогноз\n",
    "  with torch.no_grad():\n",
    "      # Прямой проход, расчет прогнозов логитов\n",
    "      outputs = model(b_input_ids, token_type_ids=None,\n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Перемещаем логиты и метки на CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  # Сохраняем прогнозы и истинные метки\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    ГОТОВО.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выведем отношение хороших текстов к общему количеству"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Положительные примеры: 733 из 983 (74.57%)\n"
     ]
    }
   ],
   "source": [
    "print('Положительные примеры: %d из %d (%.2f%%)' % (test_df.acceptable.sum(), len(test_df.acceptable), (test_df.acceptable.sum() / len(test_df.acceptable) * 100.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посчитаем коэффициент корреляции Мэтьюса для каждого батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расчет коэффициента корреляции Мэтьюса для каждого батча...\n"
     ]
    }
   ],
   "source": [
    "matthews_set = []\n",
    "\n",
    "# Оцениваем каждый тестовый батч с использованием коэффициента корреляции Мэтьюса\n",
    "print('Расчет коэффициента корреляции Мэтьюса для каждого батча...')\n",
    "\n",
    "# Для каждого входного батча...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "  # Прогнозы для этого батча - это ndarray из 2 столбцов (один столбец для \"0\"\n",
    "  # и один столбец для \"1\"). Выбираем метку с наивысшим значением и превращаем это\n",
    "  # в список из 0 и 1.\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "  # Рассчитываем и сохраняем коэффициент для этого батча.\n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
    "  matthews_set.append(matthews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выведем общий MCC для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общий MCC: 0.380\n"
     ]
    }
   ],
   "source": [
    "# Объединяем результаты по всем батчам.\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Для каждого образца выбираем метку (0 или 1) с более высоким значением.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Объединяем правильные метки для каждого батча в единый список.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Рассчитываем коэффициент корреляции Мэтьюса (MCC)\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Общий MCC: %.3f' % mcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "почистим наш гпу... памяти мало... Очень странно но пока не перегонял на цпу - очистка не шла. и даже после этого она была не полноценной, но лучше чем ничего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ai-forever/rugpt3small_based_on_gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50264, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(phrase: str,\n",
    "                        tokenizer,\n",
    "                        model):\n",
    "\n",
    "    phrase = tokenizer.encode(phrase)\n",
    "    # Если длина фразы 1 токен, то дальше ошибка вылезет :(\n",
    "    if len(phrase) == 1:\n",
    "         phrase.append(tokenizer.eos_token_id)\n",
    "    phrase = torch.tensor(phrase, dtype=torch.long, device=device)\n",
    "    phrase = phrase.unsqueeze(0)  # .repeat(num_samples, 1)\n",
    "    with torch.no_grad():\n",
    "        loss = model(phrase, labels=phrase)\n",
    "\n",
    "    loss[0].item()\n",
    "\n",
    "\n",
    "    return loss[0].item()\n",
    "\n",
    "def get_loss_num(text):\n",
    "    loss = calc_loss(phrase=text, model=model, tokenizer=tokenizer)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделаем цикл, который проверит few-shot и цикл zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество few-shot: 0\n",
      "Few-shot текст:\n",
      "     Предложение далее корректное? В Белоруссии либеральные газеты не остались.  Ответ: Нет.\n",
      "Потери: 6.528524875640869\n",
      "\n",
      "Количество few-shot: 1\n",
      "Few-shot текст:\n",
      "     Предложение далее корректное? В Белоруссии либеральные газеты не остались.  Ответ: Нет.\n",
      "     Предложение далее корректное? Иван хочет, чтобы Петр пригласил его к себе.  Ответ: Да.\n",
      "Потери: 4.452184677124023\n",
      "\n",
      "Количество few-shot: 2\n",
      "Few-shot текст:\n",
      "     Предложение далее корректное? В Белоруссии либеральные газеты не остались.  Ответ: Нет.\n",
      "     Предложение далее корректное? Иван хочет, чтобы Петр пригласил его к себе.  Ответ: Да.\n",
      "     Предложение далее корректное? Дубровский назначил Кистеневскую рощу местом свиданья.  Ответ: Да.\n",
      "Потери: 3.756847858428955\n",
      "\n",
      "Количество few-shot: 4\n",
      "Few-shot текст:\n",
      "     Предложение далее корректное? В Белоруссии либеральные газеты не остались.  Ответ: Нет.\n",
      "     Предложение далее корректное? Иван хочет, чтобы Петр пригласил его к себе.  Ответ: Да.\n",
      "     Предложение далее корректное? Дубровский назначил Кистеневскую рощу местом свиданья.  Ответ: Да.\n",
      "     Предложение далее корректное? Сейчас есть занятия по химии, физике.  Ответ: Нет.\n",
      "     Предложение далее корректное? Вечером я дописывал \"Романтиков\".  Ответ: Да.\n",
      "Потери: 3.1091535091400146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 1, 2, 4]:\n",
    "    random_samples = train_df.sample(n=i+1, random_state=42)\n",
    "\n",
    "    few_shots = \"\"\n",
    "    for index in range(i+1):\n",
    "        answer = \"Да\" if random_samples.iloc[index][\"acceptable\"] == 1 else \"Нет\"\n",
    "        few_shots += f'     Предложение далее корректное? {random_samples.iloc[index][\"sentence\"]}  Ответ: {answer}.\\n'\n",
    "\n",
    "    loss = get_loss_num(few_shots)\n",
    "    print(f'Количество few-shot: {i}\\nFew-shot текст:\\n{few_shots}Потери: {loss}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample=train_df.sample(n=1, random_state=42)\n",
    "sentence=random_sample.iloc[0][\"sentence\"]\n",
    "label=\"Да\" if random_sample.iloc[0][\"acceptable\"] == 1 else \"Нет\"\n",
    "def zero_shot(start,end):\n",
    "    text=start+sentence+end\n",
    "    loss=get_loss_num(text)\n",
    "    print(f\"Текст: {sentence}\\nОн правильный:{label}\\nТекст с затравками: {text}\\nПотери: {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: Это правильно. В Белоруссии либеральные газеты не остались. В точку.\n",
      "Потери: 5.480813980102539\n",
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: 100% В Белоруссии либеральные газеты не остались. )))\n",
      "Потери: 6.629759311676025\n",
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: ))) В Белоруссии либеральные газеты не остались. Это великолепно.\n",
      "Потери: 6.023663520812988\n",
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: Не правильно. В Белоруссии либеральные газеты не остались. Это пичалька.\n",
      "Потери: 4.9911346435546875\n",
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: 100% В Белоруссии либеральные газеты не остались. )))\n",
      "Потери: 6.629759311676025\n",
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: ))) В Белоруссии либеральные газеты не остались. )))\n",
      "Потери: 6.571372985839844\n",
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: Косяк. В Белоруссии либеральные газеты не остались. Эт дно.\n",
      "Потери: 6.1603851318359375\n",
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: Не правильно. В Белоруссии либеральные газеты не остались. Оставляет желать лучшего.\n",
      "Потери: 5.016362190246582\n",
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: 0% В Белоруссии либеральные газеты не остались. (((\n",
      "Потери: 6.440212726593018\n",
      "Текст: В Белоруссии либеральные газеты не остались.\n",
      "Он правильный:Нет\n",
      "Текст с затравками: 100% В Белоруссии либеральные газеты не остались. В точку.\n",
      "Потери: 6.034336090087891\n"
     ]
    }
   ],
   "source": [
    "def generate_random_positive_negative_combinations(num_variations=100):\n",
    "    positive_prefixes = [\n",
    "        \"Это правильно. \",\n",
    "        \"100% \",\n",
    "        \"Блестяще. \",\n",
    "        \"В десятку. \",\n",
    "        \"))) \"\n",
    "    ]\n",
    "\n",
    "    negative_prefixes = [\n",
    "        \"Не правильно. \",\n",
    "        \"Косяк. \",\n",
    "        \"0% \",\n",
    "        \"(((. \",\n",
    "        \"Фейл. \"\n",
    "    ]\n",
    "\n",
    "    positive_suffixes = [\n",
    "        \" Это великолепно.\",\n",
    "        \" )))\",\n",
    "        \" В точку.\",\n",
    "        \" Замечательно!\",\n",
    "        \" В 100-чку!\"\n",
    "    ]\n",
    "\n",
    "    negative_suffixes = [\n",
    "        \" Это пичалька.\",\n",
    "        \" Оставляет желать лучшего.\",\n",
    "        \" (((\",\n",
    "        \" Эт дно.\",\n",
    "        \" Фигня.\"\n",
    "    ]\n",
    "\n",
    "    combinations = []\n",
    "\n",
    "    for _ in range(num_variations):\n",
    "        if random.choice([True, False]):  # Randomly choose positive or negative\n",
    "            prefix = random.choice(positive_prefixes)\n",
    "            suffix = random.choice(positive_suffixes)\n",
    "        else:\n",
    "            prefix = random.choice(negative_prefixes)\n",
    "            suffix = random.choice(negative_suffixes)\n",
    "\n",
    "        combinations.append((prefix, suffix))\n",
    "\n",
    "    return combinations\n",
    "\n",
    "# приготовим пачку комбинаций\n",
    "combinations = generate_random_positive_negative_combinations(100)\n",
    "\n",
    "# бомбанем по ним зирошотом \n",
    "for i, (prefix, suffix) in enumerate(combinations[:10], 1):\n",
    "    zero_shot(prefix,suffix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "поизучал я t5 питоновский файл. Нет никаких объяснений, гора параметров и решил просто тупо попробовать обучить модельку. К тому же мне очень не понравилось что была выбрана T5ForConditionalGeneration а не T5ForSequenceClassification. Понятно, что это text-to-text model, но!!! не зря же люди голову для классификации придумывали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruT5-base and are newly initialized: ['classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight', 'classification_head.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/vlamykin/git/NLP_OTUS_2023/env/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ai-forever/ruT5-base\"\n",
    "model = T5ForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/vlamykin/git/NLP_OTUS_2023/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное предложение:  Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
      "Идентификаторы слов: tensor([ 6057, 31163, 25014,  7590,     7,     6,   619,     3,     5,     9,\n",
      "         6730,    13, 10526,   565,   305,  8092,  8504,     3, 25694,  1852,\n",
      "           57,    26,  3933,    99,  2164,     3,     5,    17, 21931,   536,\n",
      "         1759,    18,  5066,     4,     2,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Токенизируем все предложения и сопоставляем токены их идентификаторам слов.\n",
    "train_input_ids, train_attention_masks = encode(train_sentences,tokenizer)\n",
    "test_input_ids, test_attention_masks = encode(test_sentences,tokenizer)\n",
    "\n",
    "# Преобразуем списки в тензоры.\n",
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Выводим первое предложение как список идентификаторов слов.\n",
    "print('Исходное предложение: ', train_sentences[0])\n",
    "print('Идентификаторы слов:', train_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,082 образцов для обучения\n",
      "  787 образцов для валидации\n"
     ]
    }
   ],
   "source": [
    "# Создаем TensorDataset из тензоров train_input_ids, train_attention_masks и train_labels.\n",
    "dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "\n",
    "# Создаем разделение данных на обучающую и валидационную выборки в пропорции 90-10.\n",
    "# Вычисляем количество образцов в каждом наборе.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Делим набор данных, случайным образом выбирая образцы.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Выводим информацию о количестве образцов в обучающей и валидационной выборках.\n",
    "print('{:>5,} образцов для обучения'.format(train_size))\n",
    "print('{:>5,} образцов для валидации'.format(val_size))\n",
    "\n",
    "# Создаем TensorDataset для тестовых данных.\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader должен знать размер нашего батча для обучения, поэтому мы указываем его здесь.\n",
    "batch_size = 16\n",
    "\n",
    "# Создаем DataLoaders для наших обучающих и валидационных наборов данных.\n",
    "# Образцы для обучения будем брать в случайном порядке.\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # Обучающие образцы.\n",
    "            sampler = RandomSampler(train_dataset), # Выбираем батчи случайным образом.\n",
    "            batch_size = batch_size # Обучение с этим размером батча.\n",
    "        )\n",
    "\n",
    "# Для валидации порядок не имеет значения, поэтому мы просто читаем их последовательно.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # Валидационные образцы.\n",
    "            sampler = SequentialSampler(val_dataset), # Извлекаем батчи последовательно.\n",
    "            batch_size = batch_size # Оценка с этим размером батча.\n",
    "        )\n",
    "\n",
    "# DataLoader для тестовых данных.\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # Тестовые образцы.\n",
    "            sampler = SequentialSampler(test_dataset), # Извлекаем батчи последовательно.\n",
    "            batch_size = batch_size # Оценка с этим размером батча.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1 (Обучение): 100%|██████████| 443/443 [03:13<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, Средние потери при обучении: 0.611666705989138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1 (Валидация): 100%|██████████| 50/50 [00:06<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, Средние потери при валидации: 0.5153628116846085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2 (Обучение): 100%|██████████| 443/443 [03:35<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2, Средние потери при обучении: 0.5866436129498966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2, Средние потери при валидации: 0.5140694439411163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3 (Обучение): 100%|██████████| 443/443 [03:41<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 3, Средние потери при обучении: 0.5770175400827054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 3, Средние потери при валидации: 0.523694808781147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 4 (Обучение): 100%|██████████| 443/443 [03:47<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 4, Средние потери при обучении: 0.5739507654988739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 4 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 4, Средние потери при валидации: 0.5274526831507683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 5 (Обучение): 100%|██████████| 443/443 [03:53<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 5, Средние потери при обучении: 0.5706363726012056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 5 (Валидация): 100%|██████████| 50/50 [00:09<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 5, Средние потери при валидации: 0.5276537251472473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 6 (Обучение): 100%|██████████| 443/443 [03:47<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 6, Средние потери при обучении: 0.5670490543406381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 6 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 6, Средние потери при валидации: 0.5081007480621338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 7 (Обучение): 100%|██████████| 443/443 [03:50<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 7, Средние потери при обучении: 0.5657402382276397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 7 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 7, Средние потери при валидации: 0.5221782553195954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 8 (Обучение): 100%|██████████| 443/443 [03:50<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 8, Средние потери при обучении: 0.5556388683028469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 8 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 8, Средние потери при валидации: 0.5094282817840576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 9 (Обучение): 100%|██████████| 443/443 [03:50<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 9, Средние потери при обучении: 0.5476830199394485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 9 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 9, Средние потери при валидации: 0.4802269423007965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 10 (Обучение): 100%|██████████| 443/443 [03:50<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 10, Средние потери при обучении: 0.5428559999433651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 10 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 10, Средние потери при валидации: 0.5038332122564316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 11 (Обучение): 100%|██████████| 443/443 [03:50<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 11, Средние потери при обучении: 0.5249400952196014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 11 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 11, Средние потери при валидации: 0.4922960931062698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 12 (Обучение): 100%|██████████| 443/443 [03:45<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 12, Средние потери при обучении: 0.5090003427345112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 12 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 12, Средние потери при валидации: 0.48351979583501814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 13 (Обучение): 100%|██████████| 443/443 [03:48<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 13, Средние потери при обучении: 0.4857067684422228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 13 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 13, Средние потери при валидации: 0.5109257110953331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 14 (Обучение): 100%|██████████| 443/443 [03:51<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 14, Средние потери при обучении: 0.4666337741046942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 14 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 14, Средние потери при валидации: 0.48466878294944765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 15 (Обучение): 100%|██████████| 443/443 [03:51<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 15, Средние потери при обучении: 0.43029277349567846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 15 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 15, Средние потери при валидации: 0.5156189016997814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 16 (Обучение): 100%|██████████| 443/443 [03:52<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 16, Средние потери при обучении: 0.39148255503204554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 16 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 16, Средние потери при валидации: 0.510189098417759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 17 (Обучение): 100%|██████████| 443/443 [03:51<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 17, Средние потери при обучении: 0.33760917146372743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 17 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 17, Средние потери при валидации: 0.5729537929594517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 18 (Обучение): 100%|██████████| 443/443 [03:51<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 18, Средние потери при обучении: 0.2737334681334264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 18 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 18, Средние потери при валидации: 0.6309373715519905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 19 (Обучение): 100%|██████████| 443/443 [03:52<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 19, Средние потери при обучении: 0.23110330735940832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 19 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 19, Средние потери при валидации: 0.6381390249729156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 20 (Обучение): 100%|██████████| 443/443 [03:51<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 20, Средние потери при обучении: 0.17925627971736557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 20 (Валидация): 100%|██████████| 50/50 [00:07<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 20, Средние потери при валидации: 0.6921372560411692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Тестирование: 100%|██████████| 62/62 [00:09<00:00,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициент корреляции Мэтьюса на тестовом наборе: 0.37409167529626774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    # Обучающий цикл\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Эпоха {epoch+1} (Обучение)\"):\n",
    "        optimizer.zero_grad()\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        outputs = model(b_input_ids, labels=b_labels, attention_mask=b_input_mask)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Эпоха {epoch+1}, Средние потери при обучении: {average_loss}\")\n",
    "\n",
    "    # Валидационный цикл\n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in tqdm(validation_dataloader, desc=f\"Эпоха {epoch+1} (Валидация)\"):\n",
    "            b_input_ids = val_batch[0].to(device)\n",
    "            b_input_mask = val_batch[1].to(device)\n",
    "            b_labels = val_batch[2].to(device)\n",
    "\n",
    "            val_outputs = model(b_input_ids, labels=b_labels, attention_mask=b_input_mask)\n",
    "            val_loss = val_outputs.loss\n",
    "            val_total_loss += val_loss.item()\n",
    "\n",
    "    val_average_loss = val_total_loss / len(validation_dataloader)\n",
    "    print(f\"Эпоха {epoch+1}, Средние потери при валидации: {val_average_loss}\")\n",
    "\n",
    "# Тестовый цикл и вычисление MCC (Коэффициент корреляции Мэтьюса)\n",
    "model.eval()\n",
    "all_test_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_batch in tqdm(test_dataloader, desc=\"Тестирование\"):\n",
    "        b_input_ids = test_batch[0].to(device)\n",
    "        b_input_mask = test_batch[1].to(device)\n",
    "        b_labels = test_batch[2].to(device)\n",
    "\n",
    "        test_outputs = model(b_input_ids, labels=b_labels, attention_mask=b_input_mask)\n",
    "        predictions = torch.argmax(test_outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "        all_test_labels.extend(b_labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions)\n",
    "\n",
    "mcc = matthews_corrcoef(all_test_labels, all_predictions)\n",
    "print(f\"Коэффициент корреляции Мэтьюса на тестовом наборе: {mcc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
